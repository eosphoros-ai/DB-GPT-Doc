"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5375],{6913:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>r,contentTitle:()=>t,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var s=o(4848),a=o(8453);const i={},t="Docker Deployment",l={id:"installation/docker",title:"Docker Deployment",description:"Docker image preparation",source:"@site/versioned_docs/version-v0.5.1/installation/docker.md",sourceDirName:"installation",slug:"/installation/docker",permalink:"/docs/v0.5.1/installation/docker",draft:!1,unlisted:!1,tags:[],version:"v0.5.1",frontMatter:{},sidebar:"docs",previous:{title:"Source Code Deployment",permalink:"/docs/v0.5.1/installation/sourcecode"},next:{title:"Docker-Compose Deployment",permalink:"/docs/v0.5.1/installation/docker_compose"}},r={},c=[{value:"Docker image preparation",id:"docker-image-preparation",level:2},{value:"Run Docker container",id:"run-docker-container",level:2},{value:"Run through Sqlite database",id:"run-through-sqlite-database",level:3},{value:"Run through MySQL database",id:"run-through-mysql-database",level:3},{value:"Run through the OpenAI proxy model",id:"run-through-the-openai-proxy-model",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"docker-deployment",children:"Docker Deployment"}),"\n",(0,s.jsx)(n.h2,{id:"docker-image-preparation",children:"Docker image preparation"}),"\n",(0,s.jsxs)(n.p,{children:["There are two ways to prepare a Docker image. 1. Pull from the official image 2. Build locally. You can ",(0,s.jsx)(n.strong,{children:"choose any one"})," during actual use."]}),"\n",(0,s.jsxs)(n.p,{children:["1.Pulled from the official image repository, ",(0,s.jsx)(n.a,{href:"https://hub.docker.com/u/eosphorosai",children:"Eosphoros AI Docker Hub"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"docker pull eosphorosai/dbgpt:latest\n"})}),"\n",(0,s.jsx)(n.p,{children:"2.local build(optional)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"bash docker/build_all_images.sh\n"})}),"\n",(0,s.jsx)(n.p,{children:"Check the Docker image"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# command\ndocker images | grep "eosphorosai/dbgpt"\n\n# result\n--------------------------------------------------------------------------------------\neosphorosai/dbgpt-allinone       latest    349d49726588   27 seconds ago       15.1GB\neosphorosai/dbgpt                latest    eb3cdc5b4ead   About a minute ago   14.5GB\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"eosphorosai/dbgpt"})," is the base image, which contains project dependencies and the sqlite database. The ",(0,s.jsx)(n.code,{children:"eosphorosai/dbgpt-allinone"})," image is built from ",(0,s.jsx)(n.code,{children:"eosphorosai/dbgpt"}),", which contains a MySQL database. Of course, in addition to pulling the Docker image, the project also provides Dockerfile files, which can be built directly through scripts in DB-GPT. Here are the build commands:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"bash docker/build_all_images.sh\n"})}),"\n",(0,s.jsx)(n.p,{children:"When using it, you need to specify specific parameters. The following is an example of specifying parameter construction:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"bash docker/build_all_images.sh \\\n--base-image nvidia/cuda:11.8.0-runtime-ubuntu22.04 \\\n--pip-index-url https://pypi.tuna.tsinghua.edu.cn/simple \\\n--language zh\n"})}),"\n",(0,s.jsxs)(n.p,{children:["You can view the specific usage through the command ",(0,s.jsx)(n.code,{children:"bash docker/build_all_images.sh --help"})]}),"\n",(0,s.jsx)(n.h2,{id:"run-docker-container",children:"Run Docker container"}),"\n",(0,s.jsx)(n.h3,{id:"run-through-sqlite-database",children:"Run through Sqlite database"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"docker run --ipc host --gpus all -d \\\n-p 5000:5000 \\\n-e LOCAL_DB_TYPE=sqlite \\\n-e LOCAL_DB_PATH=data/default_sqlite.db \\\n-e LLM_MODEL=vicuna-13b-v1.5 \\\n-e LANGUAGE=zh \\\n-v /data/models:/app/models \\\n--name dbgpt \\\neosphorosai/dbgpt\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Open the browser and visit ",(0,s.jsx)(n.a,{href:"http://localhost:5000",children:"http://localhost:5000"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-e LLM_MODEL=vicuna-13b-v1.5"}),", which means the base model uses ",(0,s.jsx)(n.code,{children:"vicuna-13b-v1.5"}),". For more model usage, you can view the configuration in ",(0,s.jsx)(n.code,{children:"/pilot/configs/model_config.LLM_MODEL_CONFIG"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-v /data/models:/app/models"}),", specifies the model file to be mounted. The directory ",(0,s.jsx)(n.code,{children:"/data/models"})," is mounted in ",(0,s.jsx)(n.code,{children:"/app/models"})," of the container. Of course, it can be replaced with other paths."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"After the container is started, you can view the logs through the following command"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"docker logs dbgpt -f\n"})}),"\n",(0,s.jsx)(n.h3,{id:"run-through-mysql-database",children:"Run through MySQL database"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"docker run --ipc host --gpus all -d -p 3306:3306 \\\n-p 5000:5000 \\\n-e LOCAL_DB_HOST=127.0.0.1 \\\n-e LOCAL_DB_PASSWORD=aa123456 \\\n-e MYSQL_ROOT_PASSWORD=aa123456 \\\n-e LLM_MODEL=vicuna-13b-v1.5 \\\n-e LANGUAGE=zh \\\n-v /data/models:/app/models \\\n--name db-gpt-allinone \\\ndb-gpt-allinone\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Open the browser and visit ",(0,s.jsx)(n.a,{href:"http://localhost:5000",children:"http://localhost:5000"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-e LLM_MODEL=vicuna-13b-v1.5"}),", which means the base model uses ",(0,s.jsx)(n.code,{children:"vicuna-13b-v1.5"}),". For more model usage, you can view the configuration in ",(0,s.jsx)(n.code,{children:"/pilot/configs/model_config.LLM_MODEL_CONFIG"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-v /data/models:/app/models"}),", specifies the model file to be mounted. The directory ",(0,s.jsx)(n.code,{children:"/data/models"})," is mounted in ",(0,s.jsx)(n.code,{children:"/app/models"})," of the container. Of course, it can be replaced with other paths."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"After the container is started, you can view the logs through the following command"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"docker logs db-gpt-allinone -f\n"})}),"\n",(0,s.jsx)(n.h3,{id:"run-through-the-openai-proxy-model",children:"Run through the OpenAI proxy model"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'PROXY_API_KEY="You api key"\nPROXY_SERVER_URL="https://api.openai.com/v1/chat/completions"\ndocker run --gpus all -d -p 3306:3306 \\\n-p 5000:5000 \\\n-e LOCAL_DB_HOST=127.0.0.1 \\\n-e LOCAL_DB_PASSWORD=aa123456 \\\n-e MYSQL_ROOT_PASSWORD=aa123456 \\\n-e LLM_MODEL=proxyllm \\\n-e PROXY_API_KEY=$PROXY_API_KEY \\\n-e PROXY_SERVER_URL=$PROXY_SERVER_URL \\\n-e LANGUAGE=zh \\\n-v /data/models/text2vec-large-chinese:/app/models/text2vec-large-chinese \\\n--name db-gpt-allinone \\\ndb-gpt-allinone\n'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-e LLM_MODEL=proxyllm"}),", set the model to serve the third-party model service API, which can be openai or fastchat interface."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"-v /data/models/text2vec-large-chinese:/app/models/text2vec-large-chinese"}),", sets the knowledge base embedding model to ",(0,s.jsx)(n.code,{children:"text2vec"})]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Open the browser and visit ",(0,s.jsx)(n.a,{href:"http://localhost:5000",children:"http://localhost:5000"})]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>t,x:()=>l});var s=o(6540);const a={},i=s.createContext(a);function t(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);