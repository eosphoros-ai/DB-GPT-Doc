"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[3104],{4310:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>c,contentTitle:()=>d,default:()=>f,frontMatter:()=>o,metadata:()=>i,toc:()=>s});var t=n(4848),r=n(8453);const o={},d="Debugging",i={id:"application_manual/advanced_tutorial/debugging",title:"Debugging",description:"DB-GPT provides a series of tools to help developers troubleshoot and solve some problems they may encounter.",source:"@site/versioned_docs/version-v0.5.1/application_manual/advanced_tutorial/debugging.md",sourceDirName:"application_manual/advanced_tutorial",slug:"/application_manual/advanced_tutorial/debugging",permalink:"/docs/v0.5.1/application_manual/advanced_tutorial/debugging",draft:!1,unlisted:!1,tags:[],version:"v0.5.1",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Chat Knowledge",permalink:"/docs/v0.5.1/application/started_tutorial/chat_knowledge"},next:{title:"RAG Parameter Adjustment",permalink:"/docs/v0.5.1/application_manual/advanced_tutorial/rag"}},c={},s=[{value:"Trace log",id:"trace-log",level:2},{value:"View chat details",id:"view-chat-details",level:2},{value:"View service runtime information",id:"view-service-runtime-information",level:2},{value:"View latest conversation information",id:"view-latest-conversation-information",level:2},{value:"View chat details and call chain",id:"view-chat-details-and-call-chain",level:2},{value:"View chat details based on trace_id",id:"view-chat-details-based-on-trace_id",level:2},{value:"More chat command usage",id:"more-chat-command-usage",level:2},{value:"View the call tree based on trace_id",id:"view-the-call-tree-based-on-trace_id",level:2},{value:"List trace information",id:"list-trace-information",level:2},{value:"View trace information based on trace type",id:"view-trace-information-based-on-trace-type",level:2},{value:"Search trace information",id:"search-trace-information",level:2},{value:"More list related command usage",id:"more-list-related-command-usage",level:2}];function l(e){const a={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.h1,{id:"debugging",children:"Debugging"}),"\n",(0,t.jsx)(a.p,{children:"DB-GPT provides a series of tools to help developers troubleshoot and solve some problems they may encounter."}),"\n",(0,t.jsx)(a.h2,{id:"trace-log",children:"Trace log"}),"\n",(0,t.jsxs)(a.p,{children:["DB-GPT writes some key system runtime information to trace logs. By default, they are located in ",(0,t.jsx)(a.code,{children:"logs/dbgpt*.jsonl"}),"."]}),"\n",(0,t.jsxs)(a.p,{children:["DB-GPT also provides a command line tool ",(0,t.jsx)(a.code,{children:"dbgpt trace"})," to help analyze these trace logs. You can check the specific usage through the following command:"]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace --help\n"})}),"\n",(0,t.jsx)(a.h2,{id:"view-chat-details",children:"View chat details"}),"\n",(0,t.jsxs)(a.p,{children:["You can view chat details through the ",(0,t.jsx)(a.code,{children:"dbgpt trace chat"})," command. By default, the latest conversation information is displayed."]}),"\n",(0,t.jsx)(a.h2,{id:"view-service-runtime-information",children:"View service runtime information"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace chat --hide_conv\n"})}),"\n",(0,t.jsx)(a.p,{children:"The output is as follows:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"+------------------------+--------------------------+-----------------------------+------------------------------------+\n| Config Key (Webserver) | Config Value (Webserver) | Config Key (EmbeddingModel) |   Config Value (EmbeddingModel)    |\n+------------------------+--------------------------+-----------------------------+------------------------------------+\n|          host          |         0.0.0.0          |          model_name         |              text2vec              |\n|          port          |           5000           |          model_path         | /app/models/text2vec-large-chinese |\n|         daemon         |          False           |            device           |                cuda                |\n|         share          |          False           |     normalize_embeddings    |                None                |\n|    remote_embedding    |          False           |                             |                                    |\n|       log_level        |           None           |                             |                                    |\n|         light          |          False           |                             |                                    |\n+------------------------+--------------------------+-----------------------------+------------------------------------+\n+--------------------------+-----------------------------+----------------------------+------------------------------+\n| Config Key (ModelWorker) |  Config Value (ModelWorker) | Config Key (WorkerManager) | Config Value (WorkerManager) |\n+--------------------------+-----------------------------+----------------------------+------------------------------+\n|        model_name        |       vicuna-13b-v1.5       |         model_name         |       vicuna-13b-v1.5        |\n|        model_path        | /app/models/vicuna-13b-v1.5 |         model_path         | /app/models/vicuna-13b-v1.5  |\n|          device          |             cuda            |        worker_type         |             None             |\n|        model_type        |         huggingface         |        worker_class        |             None             |\n|     prompt_template      |             None            |         model_type         |         huggingface          |\n|     max_context_size     |             4096            |            host            |           0.0.0.0            |\n|         num_gpus         |             None            |            port            |             5000             |\n|      max_gpu_memory      |             None            |           daemon           |            False             |\n|      cpu_offloading      |            False            |  limit_model_concurrency   |              5               |\n|        load_8bit         |            False            |         standalone         |             True             |\n|        load_4bit         |            False            |          register          |             True             |\n|        quant_type        |             nf4             |    worker_register_host    |             None             |\n|     use_double_quant     |             True            |      controller_addr       |    http://127.0.0.1:5000     |\n|      compute_dtype       |             None            |       send_heartbeat       |             True             |\n|    trust_remote_code     |             True            |     heartbeat_interval     |              20              |\n|         verbose          |            False            |         log_level          |             None             |\n+--------------------------+-----------------------------+----------------------------+------------------------------+\n"})}),"\n",(0,t.jsx)(a.h2,{id:"view-latest-conversation-information",children:"View latest conversation information"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace chat --hide_run_params\n"})}),"\n",(0,t.jsx)(a.p,{children:"The output is as follows:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"+-------------------------------------------------------------------------------------------------------------------------------------------+\n|                                                             Chat Trace Details                                                            |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n|      Key       |                                                       Value Value                                                        |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n|    trace_id    |                                           5d1900c3-5aad-4159-9946-fbb600666530                                           |\n|    span_id     |                        5d1900c3-5aad-4159-9946-fbb600666530:14772034-bed4-4b4e-b43f-fcf3a8aad6a7                         |\n|    conv_uid    |                                           5e456272-68ac-11ee-9fba-0242ac150003                                           |\n|   user_input   |                                                       Who are you?                                                       |\n|   chat_mode    |                                                       chat_normal                                                        |\n|  select_param  |                                                           None                                                           |\n|   model_name   |                                                     vicuna-13b-v1.5                                                      |\n|  temperature   |                                                           0.6                                                            |\n| max_new_tokens |                                                           1024                                                           |\n|      echo      |                                                          False                                                           |\n|  llm_adapter   |                        FastChatLLMModelAdaperWrapper(fastchat.model.model_adapter.VicunaAdapter)                         |\n|  User prompt   | A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polit |\n|                |                             e answers to the user's questions. USER: Who are you? ASSISTANT:                             |\n|  Model output  |  You can call me Vicuna, and I was trained by Large Model Systems Organization (LMSYS) researchers as a language model.  |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n"})}),"\n",(0,t.jsx)(a.h2,{id:"view-chat-details-and-call-chain",children:"View chat details and call chain"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace chat --hide_run_params --tree\n"})}),"\n",(0,t.jsx)(a.p,{children:"The output is as follows:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"\nInvoke Trace Tree:\n\nOperation: DB-GPT-Web-Entry (Start: 2023-10-12 03:06:43.180, End: None)\n  Operation: get_chat_instance (Start: 2023-10-12 03:06:43.258, End: None)\n  Operation: get_chat_instance (Start: 2023-10-12 03:06:43.258, End: 2023-10-12 03:06:43.424)\n  Operation: stream_generator (Start: 2023-10-12 03:06:43.425, End: None)\n    Operation: BaseChat.stream_call (Start: 2023-10-12 03:06:43.426, End: None)\n      Operation: WorkerManager.generate_stream (Start: 2023-10-12 03:06:43.426, End: None)\n        Operation: DefaultModelWorker.generate_stream (Start: 2023-10-12 03:06:43.428, End: None)\n          Operation: DefaultModelWorker_call.generate_stream_func (Start: 2023-10-12 03:06:43.430, End: None)\n          Operation: DefaultModelWorker_call.generate_stream_func (Start: 2023-10-12 03:06:43.430, End: 2023-10-12 03:06:48.518)\n        Operation: DefaultModelWorker.generate_stream (Start: 2023-10-12 03:06:43.428, End: 2023-10-12 03:06:48.518)\n      Operation: WorkerManager.generate_stream (Start: 2023-10-12 03:06:43.426, End: 2023-10-12 03:06:48.518)\n    Operation: BaseChat.stream_call (Start: 2023-10-12 03:06:43.426, End: 2023-10-12 03:06:48.519)\n  Operation: stream_generator (Start: 2023-10-12 03:06:43.425, End: 2023-10-12 03:06:48.519)\nOperation: DB-GPT-Web-Entry (Start: 2023-10-12 03:06:43.180, End: 2023-10-12 03:06:43.257)\n+-------------------------------------------------------------------------------------------------------------------------------------------+\n|                                                             Chat Trace Details                                                            |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n|      Key       |                                                       Value Value                                                        |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n|    trace_id    |                                           5d1900c3-5aad-4159-9946-fbb600666530                                           |\n|    span_id     |                        5d1900c3-5aad-4159-9946-fbb600666530:14772034-bed4-4b4e-b43f-fcf3a8aad6a7                         |\n|    conv_uid    |                                           5e456272-68ac-11ee-9fba-0242ac150003                                           |\n|   user_input   |                                                       Who are you?                                                       |\n|   chat_mode    |                                                       chat_normal                                                        |\n|  select_param  |                                                           None                                                           |\n|   model_name   |                                                     vicuna-13b-v1.5                                                      |\n|  temperature   |                                                           0.6                                                            |\n| max_new_tokens |                                                           1024                                                           |\n|      echo      |                                                          False                                                           |\n|  llm_adapter   |                        FastChatLLMModelAdaperWrapper(fastchat.model.model_adapter.VicunaAdapter)                         |\n|  User prompt   | A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polit |\n|                |                             e answers to the user's questions. USER: Who are you? ASSISTANT:                             |\n|  Model output  |  You can call me Vicuna, and I was trained by Large Model Systems Organization (LMSYS) researchers as a language model.  |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n"})}),"\n",(0,t.jsx)(a.h2,{id:"view-chat-details-based-on-trace_id",children:"View chat details based on trace_id"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace chat --hide_run_params --trace_id ec30d733-7b35-4d61-b02e-2832fd2e29ff\n"})}),"\n",(0,t.jsx)(a.p,{children:"The output is as follows:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"+-------------------------------------------------------------------------------------------------------------------------------------------+\n|                                                             Chat Trace Details                                                            |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n|      Key       |                                                       Value Value                                                        |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n|    trace_id    |                                           ec30d733-7b35-4d61-b02e-2832fd2e29ff                                           |\n|    span_id     |                        ec30d733-7b35-4d61-b02e-2832fd2e29ff:0482a0c5-38b3-4b38-8101-e42489f90ccd                         |\n|    conv_uid    |                                           87a722de-68ae-11ee-9fba-0242ac150003                                           |\n|   user_input   |                                                          Hello                                                           |\n|   chat_mode    |                                                       chat_normal                                                        |\n|  select_param  |                                                           None                                                           |\n|   model_name   |                                                     vicuna-13b-v1.5                                                      |\n|  temperature   |                                                           0.6                                                            |\n| max_new_tokens |                                                           1024                                                           |\n|      echo      |                                                          False                                                           |\n|  llm_adapter   |                        FastChatLLMModelAdaperWrapper(fastchat.model.model_adapter.VicunaAdapter)                         |\n|  User prompt   | A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polit |\n|                |                                e answers to the user's questions. USER: Hello ASSISTANT:                                 |\n|  Model output  | Hello! How can I help you today? Is there something specific you want to know or talk about? I'm here to answer any ques |\n|                |                                     tions you might have, to the best of my ability.                                     |\n+----------------+--------------------------------------------------------------------------------------------------------------------------+\n"})}),"\n",(0,t.jsx)(a.h2,{id:"more-chat-command-usage",children:"More chat command usage"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"# command\ndbgpt trace chat --help\n\n# output\nUsage: dbgpt trace chat [OPTIONS] [FILES]...\n\n  Show conversation details\n\nOptions:\n  --trace_id TEXT                 Specify the trace ID to analyze. If None,\n                                  show latest conversation details\n  --tree                          Display trace spans as a tree\n  --hide_conv                     Hide your conversation details\n  --hide_run_params               Hide run params\n  --output [text|html|csv|latex|json]\n                                  The output format\n  --help                          Show this message and exit.\n"})}),"\n",(0,t.jsx)(a.h2,{id:"view-the-call-tree-based-on-trace_id",children:"View the call tree based on trace_id"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace chat --help\n"})}),"\n",(0,t.jsx)(a.p,{children:"The output is as follows:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"Operation: DB-GPT-Web-Entry (Start: 2023-10-12 03:22:10.592, End: None)\n  Operation: get_chat_instance (Start: 2023-10-12 03:22:10.594, End: None)\n  Operation: get_chat_instance (Start: 2023-10-12 03:22:10.594, End: 2023-10-12 03:22:10.658)\n  Operation: stream_generator (Start: 2023-10-12 03:22:10.659, End: None)\n    Operation: BaseChat.stream_call (Start: 2023-10-12 03:22:10.659, End: None)\n      Operation: WorkerManager.generate_stream (Start: 2023-10-12 03:22:10.660, End: None)\n        Operation: DefaultModelWorker.generate_stream (Start: 2023-10-12 03:22:10.675, End: None)\n          Operation: DefaultModelWorker_call.generate_stream_func (Start: 2023-10-12 03:22:10.676, End: None)\n          Operation: DefaultModelWorker_call.generate_stream_func (Start: 2023-10-12 03:22:10.676, End: 2023-10-12 03:22:16.130)\n        Operation: DefaultModelWorker.generate_stream (Start: 2023-10-12 03:22:10.675, End: 2023-10-12 03:22:16.130)\n      Operation: WorkerManager.generate_stream (Start: 2023-10-12 03:22:10.660, End: 2023-10-12 03:22:16.130)\n    Operation: BaseChat.stream_call (Start: 2023-10-12 03:22:10.659, End: 2023-10-12 03:22:16.130)\n  Operation: stream_generator (Start: 2023-10-12 03:22:10.659, End: 2023-10-12 03:22:16.130)\nOperation: DB-GPT-Web-Entry (Start: 2023-10-12 03:22:10.592, End: 2023-10-12 03:22:10.673)\n"})}),"\n",(0,t.jsx)(a.h2,{id:"list-trace-information",children:"List trace information"}),"\n",(0,t.jsx)(a.p,{children:"List all Trace information"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace list\n"})}),"\n",(0,t.jsx)(a.p,{children:"The output is as follows:"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"+--------------------------------------+---------------------------------------------------------------------------+-----------------------------------+------------------+\n|               Trace ID               |                                  Span ID                                  |           Operation Name          | Conversation UID |\n+--------------------------------------+---------------------------------------------------------------------------+-----------------------------------+------------------+\n| eaf4830f-976f-45a4-9a50-244f3ab6f9e1 | eaf4830f-976f-45a4-9a50-244f3ab6f9e1:f650065f-f761-4790-99f7-8109c15f756a |           run_webserver           |       None       |\n| eaf4830f-976f-45a4-9a50-244f3ab6f9e1 | eaf4830f-976f-45a4-9a50-244f3ab6f9e1:b2ff279e-0557-4b2d-8959-85e25dcfe94e |        EmbeddingLoader.load       |       None       |\n| eaf4830f-976f-45a4-9a50-244f3ab6f9e1 | eaf4830f-976f-45a4-9a50-244f3ab6f9e1:b2ff279e-0557-4b2d-8959-85e25dcfe94e |        EmbeddingLoader.load       |       None       |\n| eaf4830f-976f-45a4-9a50-244f3ab6f9e1 | eaf4830f-976f-45a4-9a50-244f3ab6f9e1:3e8b1b9d-5ef2-4382-af62-6b2b21cc04fd | WorkerManager._start_local_worker |       None       |\n| eaf4830f-976f-45a4-9a50-244f3ab6f9e1 | eaf4830f-976f-45a4-9a50-244f3ab6f9e1:3e8b1b9d-5ef2-4382-af62-6b2b21cc04fd | WorkerManager._start_local_worker |       None       |\n| eaf4830f-976f-45a4-9a50-244f3ab6f9e1 | eaf4830f-976f-45a4-9a50-244f3ab6f9e1:4c280ec9-0fd6-4ee8-b79f-1afcab0f9901 |      DefaultModelWorker.start     |       None       |\n+--------------------------------------+---------------------------------------------------------------------------+-----------------------------------+------------------+\n"})}),"\n",(0,t.jsx)(a.h2,{id:"view-trace-information-based-on-trace-type",children:"View trace information based on trace type"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace list --span_type chat\n\n+--------------------------------------+---------------------------------------------------------------------------+-------------------+--------------------------------------+\n|               Trace ID               |                                  Span ID                                  |   Operation Name  |           Conversation UID           |\n+--------------------------------------+---------------------------------------------------------------------------+-------------------+--------------------------------------+\n| 5d1900c3-5aad-4159-9946-fbb600666530 | 5d1900c3-5aad-4159-9946-fbb600666530:14772034-bed4-4b4e-b43f-fcf3a8aad6a7 | get_chat_instance | 5e456272-68ac-11ee-9fba-0242ac150003 |\n| 5d1900c3-5aad-4159-9946-fbb600666530 | 5d1900c3-5aad-4159-9946-fbb600666530:14772034-bed4-4b4e-b43f-fcf3a8aad6a7 | get_chat_instance | 5e456272-68ac-11ee-9fba-0242ac150003 |\n| ec30d733-7b35-4d61-b02e-2832fd2e29ff | ec30d733-7b35-4d61-b02e-2832fd2e29ff:0482a0c5-38b3-4b38-8101-e42489f90ccd | get_chat_instance | 87a722de-68ae-11ee-9fba-0242ac150003 |\n| ec30d733-7b35-4d61-b02e-2832fd2e29ff | ec30d733-7b35-4d61-b02e-2832fd2e29ff:0482a0c5-38b3-4b38-8101-e42489f90ccd | get_chat_instance | 87a722de-68ae-11ee-9fba-0242ac150003 |\n+--------------------------------------+---------------------------------------------------------------------------+-------------------+--------------------------------------+\n"})}),"\n",(0,t.jsx)(a.h2,{id:"search-trace-information",children:"Search trace information"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:"dbgpt trace list --search Hello\n\n+--------------------------------------+---------------------------------------------------------------------------+----------------------------------------------+--------------------------------------+\n|               Trace ID               |                                  Span ID                                  |                Operation Name                |           Conversation UID           |\n+--------------------------------------+---------------------------------------------------------------------------+----------------------------------------------+--------------------------------------+\n| ec30d733-7b35-4d61-b02e-2832fd2e29ff | ec30d733-7b35-4d61-b02e-2832fd2e29ff:0482a0c5-38b3-4b38-8101-e42489f90ccd |              get_chat_instance               | 87a722de-68ae-11ee-9fba-0242ac150003 |\n| ec30d733-7b35-4d61-b02e-2832fd2e29ff | ec30d733-7b35-4d61-b02e-2832fd2e29ff:0482a0c5-38b3-4b38-8101-e42489f90ccd |              get_chat_instance               | 87a722de-68ae-11ee-9fba-0242ac150003 |\n| ec30d733-7b35-4d61-b02e-2832fd2e29ff | ec30d733-7b35-4d61-b02e-2832fd2e29ff:03de6c87-34d6-426a-85e8-7d46d475411e |             BaseChat.stream_call             |                 None                 |\n| ec30d733-7b35-4d61-b02e-2832fd2e29ff | ec30d733-7b35-4d61-b02e-2832fd2e29ff:03de6c87-34d6-426a-85e8-7d46d475411e |             BaseChat.stream_call             |                 None                 |\n| ec30d733-7b35-4d61-b02e-2832fd2e29ff | ec30d733-7b35-4d61-b02e-2832fd2e29ff:19593596-b4c7-4d15-a3c1-0924d86098dd | DefaultModelWorker_call.generate_stream_func |                 None                 |\n| ec30d733-7b35-4d61-b02e-2832fd2e29ff | ec30d733-7b35-4d61-b02e-2832fd2e29ff:19593596-b4c7-4d15-a3c1-0924d86098dd | DefaultModelWorker_call.generate_stream_func |                 None                 |\n+--------------------------------------+---------------------------------------------------------------------------+----------------------------------------------+--------------------------------------+\n"})}),"\n",(0,t.jsx)(a.h2,{id:"more-list-related-command-usage",children:"More list related command usage"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-python",children:'dbgpt trace list --help\n\nUsage: dbgpt trace list [OPTIONS] [FILES]...\n\n  List your trace spans\n\nOptions:\n  --trace_id TEXT                 Specify the trace ID to list\n  --span_id TEXT                  Specify the Span ID to list.\n  --span_type TEXT                Specify the Span Type to list.\n  --parent_span_id TEXT           Specify the Parent Span ID to list.\n  --search TEXT                   Search trace_id, span_id, parent_span_id,\n                                  operation_name or content in metadata.\n  -l, --limit INTEGER             Limit the number of recent span displayed.\n  --start_time TEXT               Filter by start time. Format: "YYYY-MM-DD\n                                  HH:MM:SS.mmm"\n  --end_time TEXT                 Filter by end time. Format: "YYYY-MM-DD\n                                  HH:MM:SS.mmm"\n  --desc                          Whether to use reverse sorting. By default,\n                                  sorting is based on start time.\n  --output [text|html|csv|latex|json]\n                                  The output format\n  --help                          Show this message and exit.\n'})})]})}function f(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>d,x:()=>i});var t=n(6540);const r={},o=t.createContext(r);function d(e){const a=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function i(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:d(e.components),t.createElement(o.Provider,{value:a},e.children)}}}]);