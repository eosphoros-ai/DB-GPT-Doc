"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5563],{8618:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>g,frontMatter:()=>i,metadata:()=>o,toc:()=>d});var n=a(4848),s=a(8453);const i={},r="Crawl data analysis agents",o={id:"application/started_tutorial/agents/crawl_data_analysis_agents",title:"Crawl data analysis agents",description:"In this case, the usage of an agent that automatcally writes programs to scrape internet data and perform analysis is demonstrated. One can observe through natural language interaction how the agent step by step completes the code writing process, and accomplishes the task handling. Unlike data analysis agents, the agent handles everything from code writing to data scraping and analysis autonomously, supporting direct data crawling from the internet for analysis.",source:"@site/versioned_docs/version-v0.5.0/application/started_tutorial/agents/crawl_data_analysis_agents.md",sourceDirName:"application/started_tutorial/agents",slug:"/application/started_tutorial/agents/crawl_data_analysis_agents",permalink:"/docs/v0.5.0/application/started_tutorial/agents/crawl_data_analysis_agents",draft:!1,unlisted:!1,tags:[],version:"v0.5.0",frontMatter:{},sidebar:"docs",previous:{title:"Local Data Analysis Agents",permalink:"/docs/v0.5.0/application/started_tutorial/agents/db_data_analysis_agents"},next:{title:"RAG Parameter Adjustment",permalink:"/docs/v0.5.0/application/advanced_tutorial/rag"}},l={},d=[{value:"How to use?",id:"how-to-use",level:2},{value:"Write the agent",id:"write-the-agent",level:3},{value:"Insert Metadata",id:"insert-metadata",level:3},{value:"Select Dialogue Scenario",id:"select-dialogue-scenario",level:3},{value:"Start Dialogue",id:"start-dialogue",level:3}];function c(e){const t={admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"crawl-data-analysis-agents",children:"Crawl data analysis agents"}),"\n",(0,n.jsx)(t.p,{children:"In this case, the usage of an agent that automatcally writes programs to scrape internet data and perform analysis is demonstrated. One can observe through natural language interaction how the agent step by step completes the code writing process, and accomplishes the task handling. Unlike data analysis agents, the agent handles everything from code writing to data scraping and analysis autonomously, supporting direct data crawling from the internet for analysis."}),"\n",(0,n.jsx)(t.h2,{id:"how-to-use",children:"How to use?"}),"\n",(0,n.jsx)(t.p,{children:"Below are the steps for using the data scraping and analysis agent:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Write the agent"}),": in this case, we have already prepared the code writing assistant CodeAssistantAgent, with the source code located at dbgpt/agent/agents/expand/code_assistant_agent.py"]}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.strong,{children:"Insert Metadata"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.strong,{children:"Select Dialogue Scenario"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.strong,{children:"Start Dialogue"})}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"write-the-agent",children:"Write the agent"}),"\n",(0,n.jsxs)(t.p,{children:["In this case, the agent has already been programmed in the code, and the detailed code path is ",(0,n.jsx)(t.code,{children:"dbgpt/agent/agents/expand/code_assistant_agent.py"}),". The specifics of the code are as follows."]}),"\n",(0,n.jsx)(t.admonition,{title:"note",type:"info",children:(0,n.jsxs)(t.p,{children:["At the same time, under the ",(0,n.jsx)(t.code,{children:"dbgpt/agent/agents/expand"})," path, several other Agents have been implemented. Interested students can expand on their own."]})}),"\n",(0,n.jsx)("p",{align:"left",children:(0,n.jsx)("img",{src:"/img/agents/code_agent.png",width:"720px"})}),"\n",(0,n.jsx)(t.h3,{id:"insert-metadata",children:"Insert Metadata"}),"\n",(0,n.jsx)(t.p,{children:"The purpose of inserting metadata is to enable us to interact with the agent through the interactive interface."}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-sql",children:'INSERT INTO dbgpt.gpts_instance\n(gpts_name, gpts_describe, resource_db, resource_internet, resource_knowledge, gpts_agents, gpts_models, `language`, user_code, sys_code, created_at, updated_at, team_mode, is_sustainable)\nVALUES    (\n          \'\u4e92\u8054\u7f51\u6570\u636e\u5206\u6790\u52a9\u624b\',\n          \'\u4e92\u8054\u7f51\u6570\u636e\u5206\u6790\u52a9\u624b\',\n          \'\',\n          \'{"type": "\\\\u4e92\\\\u8054\\\\u7f51\\\\u6570\\\\u636e", "name": "\\\\u6240\\\\u6709\\\\u6765\\\\u6e90\\\\u4e92\\\\u8054\\\\u7f51\\\\u7684\\\\u6570\\\\u636e", "introduce": "string"}\',\n          \'{"type": "\\\\u6587\\\\u6863\\\\u7a7a\\\\u95f4", "name": "TY", "introduce": " MYSQL\\\\u6570\\\\u636e\\\\u5e93\\\\u7684\\\\u5b98\\\\u65b9\\\\u64cd\\\\u4f5c\\\\u624b\\\\u518c"}\',\n          \'[ "CodeEngineer"]\',\n          \'{"DataScientist": ["vicuna-13b-v1.5", "tongyi_proxyllm", "chatgpt_proxyllm"], "CodeEngineer": ["chatgpt_proxyllm", "tongyi_proxyllm", "vicuna-13b-v1.5"], "default": ["chatgpt_proxyllm", "tongyi_proxyllm", "vicuna-13b-v1.5"]}\',\n          \'en\',\n          \'\',\n          \'\',\n          \'2023-12-19 01:52:30\',\n          \'2023-12-19 01:52:30\',\n          \'auto_plan\',\n          0\n          );\n'})}),"\n",(0,n.jsx)(t.h3,{id:"select-dialogue-scenario",children:"Select Dialogue Scenario"}),"\n",(0,n.jsxs)(t.p,{children:["We choose ",(0,n.jsx)(t.code,{children:"Agent Chat"})," scene."]}),"\n",(0,n.jsx)("p",{align:"left",children:(0,n.jsx)("img",{src:"/img/agents/agent_scene.png",width:"720px"})}),"\n",(0,n.jsxs)(t.p,{children:["After entering the scene, select the ",(0,n.jsx)(t.code,{children:"Internet Data Analysis Assistant Agent"})," that we have just prepared, and then you can fulfill the requirements through a dialogue."]}),"\n",(0,n.jsx)("p",{align:"left",children:(0,n.jsx)("img",{src:"/img/agents/crawl_agent.png",width:"720px"})}),"\n",(0,n.jsx)(t.h3,{id:"start-dialogue",children:"Start Dialogue"}),"\n",(0,n.jsxs)(t.blockquote,{children:["\n",(0,n.jsx)(t.p,{children:"To obtain and analyze the issue data for the 'eosphoros-ai/DB-GPT' repository over the past week and create a Markdown table grouped by day and status."}),"\n"]}),"\n",(0,n.jsx)("p",{align:"left",children:(0,n.jsx)("img",{src:"/img/agents/crawl_agent_issue.png",width:"720px"})})]})}function g(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},8453:(e,t,a)=>{a.d(t,{R:()=>r,x:()=>o});var n=a(6540);const s={},i=n.createContext(s);function r(e){const t=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);