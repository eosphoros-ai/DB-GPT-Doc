"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5318],{3526:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>l,metadata:()=>d,toc:()=>p});var r=n(4848),o=n(8453),a=n(1470),s=n(9365);const l={},i="RAG With AWEL",d={id:"awel/cookbook/first_rag_with_awel",title:"RAG With AWEL",description:"In this example, we will show how to use the AWEL library to create a RAG program.",source:"@site/docs/awel/cookbook/first_rag_with_awel.md",sourceDirName:"awel/cookbook",slug:"/awel/cookbook/first_rag_with_awel",permalink:"/docs/latest/awel/cookbook/first_rag_with_awel",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Multi-Round Chat with LLMs",permalink:"/docs/latest/awel/cookbook/multi_round_chat_withllm"},next:{title:"AWEL Tutorial",permalink:"/docs/latest/awel/tutorial"}},c={},p=[{value:"Install Dependencies",id:"install-dependencies",level:3},{value:"Prepare Embedding Model",id:"prepare-embedding-model",level:3},{value:"Load Knowledge And Store In Vector Store",id:"load-knowledge-and-store-in-vector-store",level:3},{value:"Retrieve Knowledge From Vector Store",id:"retrieve-knowledge-from-vector-store",level:3},{value:"Prepare LLM",id:"prepare-llm",level:3},{value:"Create RAG Program",id:"create-rag-program",level:3},{value:"Full Code",id:"full-code",level:3},{value:"Visualize DAGs",id:"visualize-dags",level:3}];function u(e){const t={a:"a",code:"code",h1:"h1",h3:"h3",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.h1,{id:"rag-with-awel",children:"RAG With AWEL"}),"\n",(0,r.jsx)(t.p,{children:"In this example, we will show how to use the AWEL library to create a RAG program."}),"\n",(0,r.jsxs)(t.p,{children:["Now, let us create a python file ",(0,r.jsx)(t.code,{children:"first_rag_with_awel.py"}),"."]}),"\n",(0,r.jsx)(t.p,{children:"In this example, we will load your knowledge from a URL and store it in a vector store."}),"\n",(0,r.jsx)(t.h3,{id:"install-dependencies",children:"Install Dependencies"}),"\n",(0,r.jsxs)(t.p,{children:["First, you need to install the ",(0,r.jsx)(t.code,{children:"dbgpt"})," library."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:'pip install "dbgpt[rag]>=0.5.2"\n'})}),"\n",(0,r.jsx)(t.h3,{id:"prepare-embedding-model",children:"Prepare Embedding Model"}),"\n",(0,r.jsx)(t.p,{children:"To store the knowledge in a vector store, we need an embedding model, DB-GPT supports\na lot of embedding models, here are some of them:"}),"\n","\n","\n",(0,r.jsxs)(a.A,{defaultValue:"openai",values:[{label:"Open AI(API)",value:"openai"},{label:"text2vec(local)",value:"text2vec"},{label:"Embedding API Server(cluster)",value:"remote_embedding"}],children:[(0,r.jsx)(s.A,{value:"openai",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"from dbgpt.rag.embedding import DefaultEmbeddingFactory\n\nembeddings = DefaultEmbeddingFactory.openai()\n"})})}),(0,r.jsx)(s.A,{value:"text2vec",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from dbgpt.rag.embedding import DefaultEmbeddingFactory\n\nembeddings = DefaultEmbeddingFactory.default("/data/models/text2vec-large-chinese")\n'})})}),(0,r.jsxs)(s.A,{value:"remote_embedding",children:[(0,r.jsxs)(t.p,{children:["If you have deployed ",(0,r.jsx)(t.a,{href:"/docs/installation/model_service/cluster",children:"DB-GPT cluster"})," and\n",(0,r.jsx)(t.a,{href:"/docs/installation/advanced_usage/OpenAI_SDK_call",children:"API server"}),"\n, you can connect to the API server to get the embeddings."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from dbgpt.rag.embedding import DefaultEmbeddingFactory\n\nembeddings = DefaultEmbeddingFactory.remote(\n  api_url="http://localhost:8100/api/v1/embeddings",\n  api_key="{your_api_key}",\n  model_name="text2vec"\n)\n'})})]})]}),"\n",(0,r.jsx)(t.h3,{id:"load-knowledge-and-store-in-vector-store",children:"Load Knowledge And Store In Vector Store"}),"\n",(0,r.jsx)(t.p,{children:"Then we can create a DAG which loads the knowledge from a URL and stores it in a vector\nstore."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import asyncio\nimport shutil\nfrom dbgpt.core.awel import DAG\nfrom dbgpt.rag import ChunkParameters\nfrom dbgpt.rag.knowledge import KnowledgeType\nfrom dbgpt.rag.operators import EmbeddingAssemblerOperator, KnowledgeOperator\nfrom dbgpt.storage.vector_store.chroma_store import ChromaVectorConfig\nfrom dbgpt.storage.vector_store.connector import VectorStoreConnector\n\n# Delete old vector store directory(/tmp/awel_rag_test_vector_store)\nshutil.rmtree("/tmp/awel_rag_test_vector_store", ignore_errors=True)\n\nvector_connector = VectorStoreConnector.from_default(\n    "Chroma",\n    vector_store_config=ChromaVectorConfig(\n        name="test_vstore",\n        persist_path="/tmp/awel_rag_test_vector_store",\n    ),\n    embedding_fn=embeddings\n)\n\nwith DAG("load_knowledge_dag") as knowledge_dag:\n    # Load knowledge from URL\n    knowledge_task = KnowledgeOperator(knowledge_type=KnowledgeType.URL.name)\n    assembler_task = EmbeddingAssemblerOperator(\n        vector_store_connector=vector_connector,\n        chunk_parameters=ChunkParameters(chunk_strategy="CHUNK_BY_SIZE")\n    )\n    knowledge_task >> assembler_task\n\nchunks = asyncio.run(assembler_task.call("https://docs.dbgpt.site/docs/latest/awel/"))\nprint(f"Chunk length: {len(chunks)}")\n'})}),"\n",(0,r.jsx)(t.h3,{id:"retrieve-knowledge-from-vector-store",children:"Retrieve Knowledge From Vector Store"}),"\n",(0,r.jsx)(t.p,{children:"Then you can retrieve the knowledge from the vector store."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'\nfrom dbgpt.core.awel import MapOperator\nfrom dbgpt.rag.operators import EmbeddingRetrieverOperator\n\nwith DAG("retriever_dag") as retriever_dag:\n    retriever_task = EmbeddingRetrieverOperator(\n        top_k=3,\n        vector_store_connector=vector_connector,\n    )\n    content_task = MapOperator(lambda cks: "\\n".join(c.content for c in cks))\n    retriever_task >> content_task\n\nchunks = asyncio.run(content_task.call("What is the AWEL?"))\nprint(chunks)\n'})}),"\n",(0,r.jsx)(t.h3,{id:"prepare-llm",children:"Prepare LLM"}),"\n",(0,r.jsx)(t.p,{children:"To build a RAG program, we need a LLM, here are some of the LLMs that DB-GPT supports:"}),"\n",(0,r.jsxs)(a.A,{defaultValue:"openai",values:[{label:"Open AI(API)",value:"openai"},{label:"YI(API)",value:"yi_proxy"},{label:"API Server(cluster)",value:"model_service"}],children:[(0,r.jsxs)(s.A,{value:"openai",children:[(0,r.jsxs)(t.p,{children:["First, you should install the ",(0,r.jsx)(t.code,{children:"openai"})," library."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"pip install openai\n"})}),(0,r.jsxs)(t.p,{children:["Then set your API key in the environment ",(0,r.jsx)(t.code,{children:"OPENAI_API_KEY"}),"."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"from dbgpt.model.proxy import OpenAILLMClient\n\nllm_client = OpenAILLMClient()\n"})})]}),(0,r.jsxs)(s.A,{value:"yi_proxy",children:[(0,r.jsx)(t.p,{children:"You should have a YI account and get the API key from the YI official website."}),(0,r.jsxs)(t.p,{children:["First, you should install the ",(0,r.jsx)(t.code,{children:"openai"})," library."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"pip install openai\n"})}),(0,r.jsxs)(t.p,{children:["Then set your API key in the environment variable ",(0,r.jsx)(t.code,{children:"YI_API_KEY"}),"."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"from dbgpt.model.proxy import YiLLMClient\n\nllm_client = YiLLMClient()\n"})})]}),(0,r.jsxs)(s.A,{value:"model_service",children:[(0,r.jsxs)(t.p,{children:["If you have deployed ",(0,r.jsx)(t.a,{href:"/docs/installation/model_service/cluster",children:"DB-GPT cluster"})," and\n",(0,r.jsx)(t.a,{href:"/docs/installation/advanced_usage/OpenAI_SDK_call",children:"API server"}),"\n, you can connect to the API server to get the LLM model."]}),(0,r.jsx)(t.p,{children:"The API is compatible with the OpenAI API, so you can use the OpenAILLMClient to\nconnect to the API server."}),(0,r.jsxs)(t.p,{children:["First you should install the ",(0,r.jsx)(t.code,{children:"openai"})," library."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"pip install openai\n"})}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from dbgpt.model.proxy import OpenAILLMClient\n\nllm_client = OpenAILLMClient(api_base="http://localhost:8100/api/v1/", api_key="{your_api_key}")\n'})})]})]}),"\n",(0,r.jsx)(t.h3,{id:"create-rag-program",children:"Create RAG Program"}),"\n",(0,r.jsx)(t.p,{children:"Lastly, we can create a RAG with the retrieved knowledge."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'\nfrom dbgpt.core.awel import InputOperator, JoinOperator, InputSource\nfrom dbgpt.core.operators import PromptBuilderOperator, RequestBuilderOperator\nfrom dbgpt.model.operators import LLMOperator\n\nprompt = """Based on the known information below, provide users with professional and concise answers to their questions. \nIf the answer cannot be obtained from the provided content, please say: \n"The information provided in the knowledge base is not sufficient to answer this question.". \nIt is forbidden to make up information randomly. When answering, it is best to summarize according to points 1.2.3.\n          known information: \n          {context}\n          question:\n          {question}\n"""\n\nwith DAG("llm_rag_dag") as rag_dag:\n    input_task = InputOperator(input_source=InputSource.from_callable())\n    retriever_task = EmbeddingRetrieverOperator(\n        top_k=3,\n        vector_store_connector=vector_connector,\n    )\n    content_task = MapOperator(lambda cks: "\\n".join(c.content for c in cks))\n    \n    merge_task = JoinOperator(lambda context, question: {"context": context, "question": question})\n    \n    prompt_task = PromptBuilderOperator(prompt)\n    # The model is gpt-3.5-turbo, you can replace it with other models.\n    req_build_task = RequestBuilderOperator(model="gpt-3.5-turbo")\n    llm_task = LLMOperator(llm_client=llm_client)\n    result_task = MapOperator(lambda r: r.text)\n\n    input_task >> retriever_task >> content_task >> merge_task\n    input_task >> merge_task\n\n    merge_task >> prompt_task >> req_build_task >> llm_task >> result_task\n\nprint(asyncio.run(result_task.call("What is the AWEL?")))\n'})}),"\n",(0,r.jsx)(t.p,{children:"The output will be:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"AWEL stands for Agentic Workflow Expression Language, which is a set of intelligent agent workflow expression language designed for large model application development. It simplifies the process by providing functionality and flexibility through its layered API design architecture, including the operator layer, AgentFrame layer, and DSL layer. Its goal is to allow developers to focus on business logic for LLMs applications without having to deal with intricate model and environment details.\n"})}),"\n",(0,r.jsx)(t.p,{children:"Congratulations! You have created a RAG program with AWEL."}),"\n",(0,r.jsx)(t.h3,{id:"full-code",children:"Full Code"}),"\n",(0,r.jsxs)(t.p,{children:["And let's look the full code of ",(0,r.jsx)(t.code,{children:"first_rag_with_awel.py"}),":"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import asyncio\nimport shutil\nfrom dbgpt.core.awel import DAG, MapOperator, InputOperator, JoinOperator, InputSource\nfrom dbgpt.core.operators import PromptBuilderOperator, RequestBuilderOperator\nfrom dbgpt.rag import ChunkParameters\nfrom dbgpt.rag.knowledge import KnowledgeType\nfrom dbgpt.rag.operators import EmbeddingAssemblerOperator, KnowledgeOperator, EmbeddingRetrieverOperator\nfrom dbgpt.rag.embedding import DefaultEmbeddingFactory\nfrom dbgpt.storage.vector_store.chroma_store import ChromaVectorConfig\nfrom dbgpt.storage.vector_store.connector import VectorStoreConnector\nfrom dbgpt.model.operators import LLMOperator\nfrom dbgpt.model.proxy import OpenAILLMClient\n\n# Here we use the openai embedding model, if you want to use other models, you can \n# replace it according to the previous example.\nembeddings = DefaultEmbeddingFactory.openai()\n# Here we use the openai LLM model, if you want to use other models, you can replace\n# it according to the previous example.\nllm_client = OpenAILLMClient()\n\n# Delete old vector store directory(/tmp/awel_rag_test_vector_store)\nshutil.rmtree("/tmp/awel_rag_test_vector_store", ignore_errors=True)\n\nvector_connector = VectorStoreConnector.from_default(\n    "Chroma",\n    vector_store_config=ChromaVectorConfig(\n        name="test_vstore",\n        persist_path="/tmp/awel_rag_test_vector_store",\n    ),\n    embedding_fn=embeddings\n)\n\nwith DAG("load_knowledge_dag") as knowledge_dag:\n    # Load knowledge from URL\n    knowledge_task = KnowledgeOperator(knowledge_type=KnowledgeType.URL.name)\n    assembler_task = EmbeddingAssemblerOperator(\n        vector_store_connector=vector_connector,\n        chunk_parameters=ChunkParameters(chunk_strategy="CHUNK_BY_SIZE")\n    )\n    knowledge_task >> assembler_task\n\nchunks = asyncio.run(assembler_task.call("https://docs.dbgpt.site/docs/latest/awel/"))\nprint(f"Chunk length: {len(chunks)}\\n")\n\n\nprompt = """Based on the known information below, provide users with professional and concise answers to their questions. \nIf the answer cannot be obtained from the provided content, please say: \n"The information provided in the knowledge base is not sufficient to answer this question.". \nIt is forbidden to make up information randomly. When answering, it is best to summarize according to points 1.2.3.\n          known information: \n          {context}\n          question:\n          {question}\n"""\n\n\nwith DAG("llm_rag_dag") as rag_dag:\n    input_task = InputOperator(input_source=InputSource.from_callable())\n    retriever_task = EmbeddingRetrieverOperator(\n        top_k=3,\n        vector_store_connector=vector_connector,\n    )\n    content_task = MapOperator(lambda cks: "\\n".join(c.content for c in cks))\n    \n    merge_task = JoinOperator(lambda context, question: {"context": context, "question": question})\n    \n    prompt_task = PromptBuilderOperator(prompt)\n    # The model is gpt-3.5-turbo, you can replace it with other models.\n    req_build_task = RequestBuilderOperator(model="gpt-3.5-turbo")\n    llm_task = LLMOperator(llm_client=llm_client)\n    result_task = MapOperator(lambda r: r.text)\n\n    input_task >> retriever_task >> content_task >> merge_task\n    input_task >> merge_task\n\n    merge_task >> prompt_task >> req_build_task >> llm_task >> result_task\n\nprint(asyncio.run(result_task.call("What is the AWEL?")))\n'})}),"\n",(0,r.jsx)(t.h3,{id:"visualize-dags",children:"Visualize DAGs"}),"\n",(0,r.jsx)(t.p,{children:"And we can visualize the DAGs with the following code:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"knowledge_dag.visualize_dag()\nrag_dag.visualize_dag()\n"})}),"\n",(0,r.jsx)(t.p,{children:"If you execute the code in Jupyter Notebook, you can see the DAGs in the notebook."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"display(knowledge_dag.show())\ndisplay(rag_dag.show())\n"})}),"\n",(0,r.jsxs)(t.p,{children:["The graph of the ",(0,r.jsx)(t.code,{children:"knowledge_dag"})," is:"]}),"\n",(0,r.jsx)("p",{align:"left",children:(0,r.jsx)("img",{src:"/img/awel/cookbook/first_rag_knowledge_dag.png",width:"1000px"})}),"\n",(0,r.jsxs)(t.p,{children:["And the graph of the ",(0,r.jsx)(t.code,{children:"rag_dag"})," is:"]}),"\n",(0,r.jsx)("p",{align:"left",children:(0,r.jsx)("img",{src:"/img/awel/cookbook/first_rag_rag_dag.png",width:"1000px"})})]})}function h(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}},9365:(e,t,n)=>{n.d(t,{A:()=>s});n(6540);var r=n(53);const o={tabItem:"tabItem_Ymn6"};var a=n(4848);function s(e){let{children:t,hidden:n,className:s}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,r.A)(o.tabItem,s),hidden:n,children:t})}},1470:(e,t,n)=>{n.d(t,{A:()=>x});var r=n(6540),o=n(53),a=n(3104),s=n(6347),l=n(205),i=n(7485),d=n(1682),c=n(9466);function p(e){return r.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:t,children:n}=e;return(0,r.useMemo)((()=>{const e=t??function(e){return p(e).map((e=>{let{props:{value:t,label:n,attributes:r,default:o}}=e;return{value:t,label:n,attributes:r,default:o}}))}(n);return function(e){const t=(0,d.X)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function h(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function m(e){let{queryString:t=!1,groupId:n}=e;const o=(0,s.W6)(),a=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,i.aZ)(a),(0,r.useCallback)((e=>{if(!a)return;const t=new URLSearchParams(o.location.search);t.set(a,e),o.replace({...o.location,search:t.toString()})}),[a,o])]}function g(e){const{defaultValue:t,queryString:n=!1,groupId:o}=e,a=u(e),[s,i]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!h({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const r=n.find((e=>e.default))??n[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:t,tabValues:a}))),[d,p]=m({queryString:n,groupId:o}),[g,_]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[o,a]=(0,c.Dv)(n);return[o,(0,r.useCallback)((e=>{n&&a.set(e)}),[n,a])]}({groupId:o}),b=(()=>{const e=d??g;return h({value:e,tabValues:a})?e:null})();(0,l.A)((()=>{b&&i(b)}),[b]);return{selectedValue:s,selectValue:(0,r.useCallback)((e=>{if(!h({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);i(e),p(e),_(e)}),[p,_,a]),tabValues:a}}var _=n(2303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var f=n(4848);function v(e){let{className:t,block:n,selectedValue:r,selectValue:s,tabValues:l}=e;const i=[],{blockElementScrollPositionUntilNextRender:d}=(0,a.a_)(),c=e=>{const t=e.currentTarget,n=i.indexOf(t),o=l[n].value;o!==r&&(d(t),s(o))},p=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const n=i.indexOf(e.currentTarget)+1;t=i[n]??i[0];break}case"ArrowLeft":{const n=i.indexOf(e.currentTarget)-1;t=i[n]??i[i.length-1];break}}t?.focus()};return(0,f.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":n},t),children:l.map((e=>{let{value:t,label:n,attributes:a}=e;return(0,f.jsx)("li",{role:"tab",tabIndex:r===t?0:-1,"aria-selected":r===t,ref:e=>i.push(e),onKeyDown:p,onClick:c,...a,className:(0,o.A)("tabs__item",b.tabItem,a?.className,{"tabs__item--active":r===t}),children:n??t},t)}))})}function w(e){let{lazy:t,children:n,selectedValue:o}=e;const a=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=a.find((e=>e.props.value===o));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return(0,f.jsx)("div",{className:"margin-top--md",children:a.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==o})))})}function k(e){const t=g(e);return(0,f.jsxs)("div",{className:(0,o.A)("tabs-container",b.tabList),children:[(0,f.jsx)(v,{...e,...t}),(0,f.jsx)(w,{...e,...t})]})}function x(e){const t=(0,_.A)();return(0,f.jsx)(k,{...e,children:p(e.children)},String(t))}},8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>l});var r=n(6540);const o={},a=r.createContext(o);function s(e){const t=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),r.createElement(a.Provider,{value:t},e.children)}}}]);